"""
æ•°æ®åˆ†ææ¨¡å—
ä½¿ç”¨ LLM å¯¹æŸ¥è¯¢ç»“æœè¿›è¡Œè‡ªç„¶è¯­è¨€åˆ†æ
"""
import logging
import pandas as pd
from typing import Dict, Any, Optional

from agent.llm import get_llm_client

logger = logging.getLogger(__name__)


def analyze_result(
        df: pd.DataFrame,
        query_plan: Dict[str, Any],
        chart_path: Optional[str] = None
) -> str:
    """
    åˆ†ææŸ¥è¯¢ç»“æœå¹¶ç”Ÿæˆè‡ªç„¶è¯­è¨€è¯´æ˜
    
    Args:
        df: æŸ¥è¯¢ç»“æœ DataFrame
        query_plan: åŸå§‹ QueryPlan
        chart_path: å›¾è¡¨è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        åˆ†æç»“æœæ–‡æœ¬
    """
    if df is None or df.empty:
        return "æŸ¥è¯¢ç»“æœä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚"

    if not query_plan:
        return "ç¼ºå°‘æŸ¥è¯¢è®¡åˆ’ä¿¡æ¯ï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚"

    try:
        llm = get_llm_client()

        # å‡†å¤‡æ•°æ®æ‘˜è¦
        data_summary = _prepare_data_summary(df)

        # æ„å»ºåˆ†ææç¤ºè¯
        messages = _build_analysis_messages(data_summary, query_plan, chart_path)

        # è°ƒç”¨ LLM è¿›è¡Œåˆ†æ
        response = llm.chat(messages=messages, temperature=0.7)

        if not response or not response.get("content"):
            return "åˆ†æç»“æœç”Ÿæˆå¤±è´¥ã€‚"

        analysis = response["content"]
        logger.info("ç»“æœåˆ†æå®Œæˆ")
        return analysis

    except Exception as e:
        logger.error(f"ç»“æœåˆ†æå¼‚å¸¸: {e}")
        return f"ç»“æœåˆ†æå¤±è´¥: {str(e)}"


def _prepare_data_summary(df: pd.DataFrame) -> str:
    """
    å‡†å¤‡ç»“æ„åŒ–æ•°æ®æ‘˜è¦
    
    Args:
        df: æ•°æ® DataFrame
        
    Returns:
        æ•°æ®æ‘˜è¦å­—ç¬¦ä¸²
    """
    if df is None or df.empty:
        return "æ•°æ®ä¸ºç©º"

    summary_parts = []

    # åŸºæœ¬ä¿¡æ¯
    row_count = len(df)
    col_count = len(df.columns)
    summary_parts.append(f"=== æ•°æ®æ¦‚è§ˆ ===")
    summary_parts.append(f"æ€»è¡Œæ•°: {row_count}, åˆ—æ•°: {col_count}")
    summary_parts.append(f"åˆ—å: {', '.join(df.columns.tolist())}")

    # å…³é”®æŒ‡æ ‡åˆ†æ
    summary_parts.append(f"\n=== å…³é”®æŒ‡æ ‡åˆ†æ ===")
    
    # åˆ†æä¸åŒåˆ—çš„é‡è¦æ€§
    if 'device_count' in df.columns and 'src_isp' in df.columns:
        # è®¾å¤‡æ•°é‡ç»Ÿè®¡åˆ†æ
        summary_parts.append(f"ğŸ“Š æ¢æµ‹è®¾å¤‡æ•°é‡ç»Ÿè®¡:")
        total_devices = df['device_count'].sum()
        summary_parts.append(f"æ€»è®¾å¤‡æ•°: {total_devices} å°")
        
        # å„è¿è¥å•†è®¾å¤‡åˆ†å¸ƒ
        device_dist = df[['src_isp', 'device_count']].to_string(index=False)
        summary_parts.append(f"\nå„è¿è¥å•†è®¾å¤‡åˆ†å¸ƒ:\n{device_dist}")
        
        # è®¾å¤‡å æ¯”åˆ†æ
        max_isp = df.loc[df['device_count'].idxmax()]
        min_isp = df.loc[df['device_count'].idxmin()]
        
        summary_parts.append(f"\nğŸ“ˆ è®¾å¤‡åˆ†å¸ƒåˆ†æ:")
        summary_parts.append(f"è®¾å¤‡æœ€å¤š: {max_isp['src_isp']} ({max_isp['device_count']} å°)")
        summary_parts.append(f"è®¾å¤‡æœ€å°‘: {min_isp['src_isp']} ({min_isp['device_count']} å°)")
        
        # è®¡ç®—è®¾å¤‡å æ¯”
        summary_parts.append(f"\nè®¾å¤‡å æ¯”:")
        for _, row in df.iterrows():
            isp = row['src_isp']
            count = row['device_count']
            percentage = (count / total_devices) * 100
            summary_parts.append(f"- {isp}: {count} å° ({percentage:.1f}%)")
        
    elif 'hostname' in df.columns and 'avg_lost' in df.columns:
        # æ¢æµ‹è®¾å¤‡åˆ†æ
        summary_parts.append(f"ğŸ“Š æ¢æµ‹è®¾å¤‡è´¨é‡æ•°æ®:")
        best_devices = df.nsmallest(3, 'avg_lost')[['hostname', 'avg_lost', 'avg_rtt']].to_string(index=False)
        worst_devices = df.nlargest(3, 'avg_lost')[['hostname', 'avg_lost', 'avg_rtt']].to_string(index=False)
        summary_parts.append(f"è´¨é‡æœ€å¥½TOP3:\n{best_devices}")
        summary_parts.append(f"è´¨é‡æœ€å·®TOP3:\n{worst_devices}")
        
    elif 'target_node' in df.columns and 'avg_lost' in df.columns:
        # ç›®æ ‡èŠ‚ç‚¹åˆ†æ
        summary_parts.append(f"ğŸ¯ ç›®æ ‡èŠ‚ç‚¹æ€§èƒ½æ•°æ®:")
        best_nodes = df.nsmallest(3, 'avg_lost')[['target_node', 'avg_lost', 'avg_rtt']].to_string(index=False)
        worst_nodes = df.nlargest(3, 'avg_lost')[['target_node', 'avg_lost', 'avg_rtt']].to_string(index=False)
        summary_parts.append(f"æ€§èƒ½æœ€ä½³TOP3:\n{best_nodes}")
        summary_parts.append(f"æ€§èƒ½æœ€å·®TOP3:\n{worst_nodes}")
        
        if 'src_isp' in df.columns:
            # æŒ‰ISPåˆ†ç»„ç»Ÿè®¡
            isp_stats = df.groupby('src_isp')['avg_lost'].agg(['mean', 'count']).round(2)
            summary_parts.append(f"\nè¿è¥å•†å¹³å‡ä¸¢åŒ…ç‡:\n{isp_stats.to_string()}")
            
    elif 'src_province' in df.columns and 'src_isp' in df.columns:
        # åœ°åŒºè¦†ç›–åˆ†æ
        summary_parts.append(f"ğŸŒ åœ°åŒºè¦†ç›–æ•°æ®:")
        province_stats = df.groupby(['src_province', 'src_isp'])['avg_lost'].mean().round(2)
        summary_parts.append(f"å„çœè¿è¥å•†å¹³å‡ä¸¢åŒ…ç‡:\n{province_stats.to_string()}")

    # æ•°å€¼åˆ—ç»Ÿè®¡æ‘˜è¦
    summary_parts.append(f"\n=== æ•°å€¼ç»Ÿè®¡ ===")
    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
    for col in ['avg_lost', 'avg_rtt', 'count']:
        if col in df.columns:
            mean_val = df[col].mean()
            max_val = df[col].max()
            min_val = df[col].min()
            median_val = df[col].median()
            summary_parts.append(f"{col}: å¹³å‡={mean_val:.2f}, ä¸­ä½æ•°={median_val:.2f}, æœ€å¤§={max_val:.2f}, æœ€å°={min_val:.2f}")

    # æ•°æ®è´¨é‡æç¤º
    summary_parts.append(f"\n=== æ•°æ®è´¨é‡æç¤º ===")
    if row_count < 10:
        summary_parts.append("âš ï¸  æ•°æ®é‡è¾ƒå°‘ï¼Œåˆ†æç»“æœå¯èƒ½ä¸å¤Ÿå…¨é¢")
    elif row_count > 1000:
        summary_parts.append("ğŸ“ˆ æ•°æ®é‡å……è¶³ï¼Œåˆ†æç»“æœå¯ä¿¡åº¦è¾ƒé«˜")
    else:
        summary_parts.append("âœ… æ•°æ®é‡é€‚ä¸­ï¼Œåˆ†æç»“æœå…·æœ‰å‚è€ƒä»·å€¼")

    return "\n".join(summary_parts)


def _build_analysis_messages(
        data_summary: str,
        query_plan: Dict[str, Any],
        chart_path: Optional[str]
) -> list:
    """
    æ„å»ºåˆ†ææç¤ºè¯
    
    Args:
        data_summary: æ•°æ®æ‘˜è¦
        query_plan: æŸ¥è¯¢è®¡åˆ’
        chart_path: å›¾è¡¨è·¯å¾„
        
    Returns:
        æ¶ˆæ¯åˆ—è¡¨
    """
    system_prompt = """ä½ æ˜¯ä¸“ä¸šçš„ç½‘ç»œæ¢æµ‹æ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿å°†åŸå§‹æ•°æ®è½¬åŒ–ä¸ºå¯æ“ä½œçš„ä¸šåŠ¡æ´å¯Ÿã€‚è¯·æ ¹æ®ç”¨æˆ·é—®é¢˜å’ŒæŸ¥è¯¢ç»“æœï¼Œæä¾›ç²¾å‡†ã€æœ‰ä»·å€¼çš„åˆ†ææŠ¥å‘Šã€‚

æ ¸å¿ƒåŸåˆ™ï¼š
1. **ç›´æ¥å›ç­”**ï¼šå¼€é—¨è§å±±å›ç­”ç”¨æˆ·æ ¸å¿ƒé—®é¢˜ï¼Œä¸è¦ç»•å¼¯å­
2. **æ•°æ®é©±åŠ¨**ï¼šåŸºäºå…·ä½“æ•°æ®å¾—å‡ºç»“è®ºï¼Œå¼•ç”¨å‡†ç¡®æ•°å€¼
3. **å¯æ“ä½œæ€§**ï¼šæä¾›æ˜ç¡®çš„å»ºè®®å’Œå†³ç­–æ”¯æŒ
4. **ç»“æ„æ¸…æ™°**ï¼šä½¿ç”¨æ’åã€å¯¹æ¯”ç­‰ç»“æ„åŒ–å‘ˆç°

åˆ†æè¦ç‚¹ï¼š
- **æ¢æµ‹è®¾å¤‡æ•°é‡åˆ†æ**ï¼šæŒ‰è¿è¥å•†ç»Ÿè®¡è®¾å¤‡æ•°é‡ï¼Œè¯†åˆ«è®¾å¤‡åˆ†å¸ƒæƒ…å†µ
- **æ¢æµ‹è®¾å¤‡è´¨é‡åˆ†æ**ï¼šè¯†åˆ«è´¨é‡æœ€å¥½/æœ€å·®çš„å…·ä½“è®¾å¤‡ï¼Œç»™å‡ºhostnameå’Œæ€§èƒ½æŒ‡æ ‡
- **ç›®æ ‡èŠ‚ç‚¹åˆ†æ**ï¼šæŒ‰ä¸¢åŒ…ç‡æ’åºï¼Œæ¨èä¼˜è´¨èŠ‚ç‚¹ï¼ŒåŒºåˆ†ä»»åŠ¡ç±»å‹
- **åœ°åŒºè¦†ç›–è¯„ä¼°**ï¼šæ˜ç¡®æ¨ètop3ç›®æ ‡èŠ‚ç‚¹ï¼Œæä¾›å…·ä½“è¦†ç›–è´¨é‡æ•°æ®

è¾“å‡ºè¦æ±‚ï¼š
1. **æ ¸å¿ƒç»“è®º**ï¼šç”¨1-2å¥è¯ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜
2. **å…³é”®æ•°æ®**ï¼šåˆ—å‡ºå‰3åæœ€å¥½å’Œæœ€å·®çš„è®¾å¤‡/èŠ‚ç‚¹ï¼ˆå«å…·ä½“æ•°å€¼ï¼‰
3. **å¯¹æ¯”åˆ†æ**ï¼šæ¨ªå‘æ¯”è¾ƒä¸åŒç»´åº¦çš„æ€§èƒ½å·®å¼‚
4. **è¡ŒåŠ¨å»ºè®®**ï¼šæä¾›2-3æ¡å…·ä½“ã€å¯æ‰§è¡Œçš„å»ºè®®

ç¦æ­¢äº‹é¡¹ï¼š
- ä¸è¯´"æŸäº›ä¸»æœº""æœ‰äº›èŠ‚ç‚¹"ç­‰æ¨¡ç³Šè¡¨è¿°
- ä¸ç¼–é€ æ•°æ®ï¼Œæ‰€æœ‰ç»“è®ºå¿…é¡»åŸºäºæŸ¥è¯¢ç»“æœ
- é¿å…ç©ºè¯å¥—è¯ï¼Œæ¯å¥è¯éƒ½è¦æœ‰ä¿¡æ¯ä»·å€¼

å›å¤æ§åˆ¶åœ¨400-600å­—ï¼Œç¡®ä¿ä¿¡æ¯å¯†é›†ä¸”å¯æ“ä½œã€‚"""

    # æå–ç”¨æˆ·åŸå§‹é—®é¢˜
    original_query = query_plan.get("original_query", "")
    if not original_query:
        original_query = "åˆ†ææŸ¥è¯¢ç»“æœ"
    
    user_prompt = f"""ç”¨æˆ·åŸå§‹é—®é¢˜ï¼š{original_query}

ğŸ“‹ æŸ¥è¯¢è®¡åˆ’ï¼š
{query_plan}

ğŸ“Š ç»“æ„åŒ–æ•°æ®æ‘˜è¦ï¼š
{data_summary}

ğŸ¯ åˆ†æè¦æ±‚ï¼š
æ ¹æ®ç”¨æˆ·é—®é¢˜çš„ç±»å‹ï¼Œè¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºåˆ†ææŠ¥å‘Šï¼š

**å¦‚æœæ˜¯æ¢æµ‹è®¾å¤‡æ•°é‡åˆ†æï¼š**
1. æ ¸å¿ƒç»“è®ºï¼šç›´æ¥å›ç­”å„è¿è¥å•†çš„è®¾å¤‡æ•°é‡åˆ†å¸ƒ
2. æ•°é‡ç»Ÿè®¡ï¼šåˆ—å‡ºå„è¿è¥å•†çš„è®¾å¤‡æ•°é‡å’Œå æ¯”
3. åˆ†å¸ƒåˆ†æï¼šåˆ†æè®¾å¤‡æ•°é‡çš„åˆ†å¸ƒç‰¹å¾
4. è¶‹åŠ¿å»ºè®®ï¼šåŸºäºè®¾å¤‡æ•°é‡ç»™å‡ºè¿ç»´å»ºè®®

**å¦‚æœæ˜¯æ¢æµ‹è®¾å¤‡è´¨é‡åˆ†æï¼š**
1. æ ¸å¿ƒç»“è®ºï¼šç›´æ¥å›ç­”å“ªäº›è®¾å¤‡è´¨é‡æœ€å¥½/æœ€å·®
2. è®¾å¤‡æ’åï¼šåˆ—å‡ºhostname + å…·ä½“ä¸¢åŒ…ç‡å’ŒRTTæ•°å€¼
3. æ€§èƒ½åˆ†å¸ƒï¼šåˆ†ææ•´ä½“è®¾å¤‡è´¨é‡åˆ†å¸ƒæƒ…å†µ
4. ä¼˜åŒ–å»ºè®®ï¼šé’ˆå¯¹è´¨é‡å·®çš„è®¾å¤‡æå‡ºå…·ä½“æ”¹è¿›æªæ–½

**å¦‚æœæ˜¯ç›®æ ‡èŠ‚ç‚¹ä¸¢åŒ…åˆ†æï¼š**
1. æ ¸å¿ƒç»“è®ºï¼šç›´æ¥å›ç­”å“ªäº›ç›®æ ‡èŠ‚ç‚¹æ€§èƒ½æœ€ä¼˜
2. èŠ‚ç‚¹æ’åï¼šæŒ‰ä¸¢åŒ…ç‡æ’åºï¼ŒåŒºåˆ†task_name
3. ä»»åŠ¡å¯¹æ¯”ï¼šä¸åŒæ¢æµ‹ä»»åŠ¡çš„æ€§èƒ½å·®å¼‚
4. é€‰æ‹©å»ºè®®ï¼šæ¨èå…·ä½“çš„ç›®æ ‡èŠ‚ç‚¹é€‰æ‹©æ–¹æ¡ˆ

**å¦‚æœæ˜¯åœ°åŒºè¦†ç›–è´¨é‡è¯„ä¼°ï¼š**
1. æ ¸å¿ƒç»“è®ºï¼šç›´æ¥å›ç­”å“ªäº›ç›®æ ‡èŠ‚ç‚¹è¦†ç›–æµ™æ±Ÿç”µä¿¡è´¨é‡æœ€å¥½
2. è¦†ç›–åˆ†æï¼šå„ç›®æ ‡èŠ‚ç‚¹åœ¨æµ™æ±Ÿç”µä¿¡çš„ä¸¢åŒ…ç‡æ’å
3. è´¨é‡è¯„ä¼°ï¼šå…·ä½“çš„ç½‘ç»œè´¨é‡æŒ‡æ ‡å’Œè¡¨ç°
4. æ¨èæ¸…å•ï¼šTOP3ä¼˜è´¨ç›®æ ‡èŠ‚ç‚¹åŠä½¿ç”¨å»ºè®®

âš ï¸  æ³¨æ„äº‹é¡¹ï¼š
- å¿…é¡»ä½¿ç”¨æ•°æ®æ‘˜è¦ä¸­çš„å…·ä½“æ•°å€¼ï¼Œä¸è¦ç¼–é€ 
- é¿å…æ¨¡ç³Šè¡¨è¿°ï¼Œè¦æ˜ç¡®æŒ‡å‡ºå…·ä½“çš„è®¾å¤‡/èŠ‚ç‚¹åç§°
- æä¾›å¯æ“ä½œçš„å»ºè®®ï¼Œè®©ç”¨æˆ·èƒ½å¤Ÿç›´æ¥å†³ç­–
- å›å¤æ§åˆ¶åœ¨500å­—ä»¥å†…ï¼Œä¿¡æ¯è¦å¯†é›†æœ‰ä»·å€¼
"""

    if chart_path:
        user_prompt += f"\nå›¾è¡¨è·¯å¾„: {chart_path}"

    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]
