"""
ç®€åŒ–æ•°æ®åˆ†æå™¨ - ç”Ÿæˆç²¾ç®€ã€é«˜ä»·å€¼çš„å›ç­”
"""
import logging
from typing import Dict, Any, Optional
import pandas as pd

logger = logging.getLogger(__name__)

def analyze_result(
    df: pd.DataFrame,
    query_plan: Dict[str, Any],
    chart_path: Optional[str] = None
) -> str:
    """
    åˆ†ææŸ¥è¯¢ç»“æœå¹¶ç”Ÿæˆç²¾ç®€çš„è‡ªç„¶è¯­è¨€è¯´æ˜
    
    Args:
        df: æŸ¥è¯¢ç»“æœ DataFrame
        query_plan: åŸå§‹ QueryPlan
        chart_path: å›¾è¡¨è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        ç²¾ç®€çš„åˆ†æç»“æœæ–‡æœ¬
    """
    if df is None or df.empty:
        return "æŸ¥è¯¢ç»“æœä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚"
    
    try:
        # æ ¹æ®æŸ¥è¯¢ç±»å‹ç”Ÿæˆç²¾ç®€åˆ†æ
        analysis_type = _determine_analysis_type(query_plan)
        
        if analysis_type == "device_count":
            return _analyze_device_count(df)
        elif analysis_type == "network_quality":
            return _analyze_network_quality(df)
        elif analysis_type == "packet_loss":
            return _analyze_packet_loss(df)
        else:
            return _generate_generic_analysis(df)
            
    except Exception as e:
        logger.error(f"ç»“æœåˆ†æå¼‚å¸¸: {e}")
        return f"ç»“æœåˆ†æå¤±è´¥: {str(e)}"


def _determine_analysis_type(query_plan: Dict[str, Any]) -> str:
    """ç¡®å®šåˆ†æç±»å‹"""
    metrics = query_plan.get("metrics", [])
    aggregation = query_plan.get("aggregation", "")
    
    if "device_count" in metrics:
        return "device_count"
    elif aggregation == "group_by_target_node":
        return "packet_loss"
    elif "avg_rtt" in metrics or "avg_lost" in metrics:
        return "network_quality"
    else:
        return "generic"


def _analyze_device_count(df: pd.DataFrame) -> str:
    """åˆ†æè®¾å¤‡æ•°é‡ç»Ÿè®¡"""
    if df.empty or 'device_count' not in df.columns:
        return "æ— æ³•åˆ†æè®¾å¤‡æ•°é‡æ•°æ®ã€‚"
    
    # æ‰¾å‡ºè®¾å¤‡æ•°é‡æœ€å¤šçš„è¿è¥å•†
    max_row = df.loc[df['device_count'].idxmax()]
    min_row = df.loc[df['device_count'].idxmin()]
    
    total_devices = df['device_count'].sum()
    isp_name = max_row.get('src_isp', 'æœªçŸ¥è¿è¥å•†')
    
    return f"""
ğŸ“Š **è®¾å¤‡åˆ†å¸ƒæ¦‚è§ˆ**

â€¢ **{isp_name}** è®¾å¤‡æœ€å¤šï¼š{max_row['device_count']}å° ({max_row['device_count']/total_devices*100:.1f}%)
â€¢ **{min_row.get('src_isp', 'æœªçŸ¥è¿è¥å•†')}** è®¾å¤‡æœ€å°‘ï¼š{min_row['device_count']}å°
â€¢ æ€»è®¡ï¼š{total_devices}å°æ¢æµ‹è®¾å¤‡

ğŸ’¡ **å»ºè®®**ï¼šå…³æ³¨è®¾å¤‡åˆ†å¸ƒå‡è¡¡æ€§ï¼Œé€‚å½“å¢åŠ è®¾å¤‡è¾ƒå°‘è¿è¥å•†çš„è¦†ç›–ã€‚
""".strip()


def _analyze_network_quality(df: pd.DataFrame) -> str:
    """åˆ†æç½‘ç»œè´¨é‡"""
    if df.empty:
        return "æ— æ³•åˆ†æç½‘ç»œè´¨é‡æ•°æ®ã€‚"
    
    avg_lost = df['avg_lost'].mean() if 'avg_lost' in df.columns else 0
    avg_rtt = df['avg_rtt'].mean() if 'avg_rtt' in df.columns else 0
    
    # è¯„ä¼°ç½‘ç»œè´¨é‡
    if avg_lost < 1 and avg_rtt < 50:
        quality = "ä¼˜ç§€"
        emoji = "ğŸŸ¢"
    elif avg_lost < 3 and avg_rtt < 100:
        quality = "è‰¯å¥½" 
        emoji = "ğŸŸ¡"
    else:
        quality = "éœ€ä¼˜åŒ–"
        emoji = "ğŸ”´"
    
    return f"""
{emoji} **ç½‘ç»œè´¨é‡è¯„ä¼°ï¼š{quality}**

â€¢ **å¹³å‡ä¸¢åŒ…ç‡**ï¼š{avg_lost:.2f}%
â€¢ **å¹³å‡å»¶è¿Ÿ**ï¼š{avg_rtt:.1f}ms

ğŸ’¡ **å»ºè®®**ï¼š{'ç½‘ç»œè´¨é‡è‰¯å¥½ï¼Œç»§ç»­ä¿æŒç›‘æ§' if quality in ['ä¼˜ç§€', 'è‰¯å¥½'] else 'å»ºè®®ä¼˜åŒ–ç½‘ç»œé…ç½®ï¼Œé‡ç‚¹æ”¹å–„ä¸¢åŒ…ç‡å’Œå»¶è¿Ÿé—®é¢˜'}ã€‚
""".strip()


def _analyze_packet_loss(df: pd.DataFrame) -> str:
    """åˆ†æä¸¢åŒ…æƒ…å†µ"""
    if df.empty or 'avg_lost_rate' not in df.columns:
        return "æ— æ³•åˆ†æä¸¢åŒ…æ•°æ®ã€‚"
    
    worst_node = df.loc[df['avg_lost_rate'].idxmax()]
    best_node = df.loc[df['avg_lost_rate'].idxmin()]
    
    avg_loss = df['avg_lost_rate'].mean()
    
    return f"""
ğŸ“ˆ **ä¸¢åŒ…ç‡åˆ†æ**

â€¢ **æ•´ä½“å¹³å‡**ï¼š{avg_loss:.2f}%
â€¢ **æœ€å·®èŠ‚ç‚¹**ï¼š{worst_node.get('target_node', 'æœªçŸ¥')} ({worst_node['avg_lost_rate']:.2f}%)
â€¢ **æœ€ä½³èŠ‚ç‚¹**ï¼š{best_node.get('target_node', 'æœªçŸ¥')} ({best_node['avg_lost_rate']:.2f}%)

ğŸ’¡ **é‡ç‚¹å…³æ³¨**ï¼šä¸¢åŒ…ç‡è¶…è¿‡3%çš„èŠ‚ç‚¹éœ€è¦ç½‘ç»œä¼˜åŒ–ã€‚
""".strip()


def _generate_generic_analysis(df: pd.DataFrame) -> str:
    """ç”Ÿæˆé€šç”¨åˆ†æ"""
    if df.empty:
        return "æ— æ•°æ®å¯åˆ†æã€‚"
    
    row_count = len(df)
    
    # æ‰¾å‡ºå…³é”®æ•°å€¼åˆ—
    numeric_cols = df.select_dtypes(include=['number']).columns
    key_insights = []
    
    for col in numeric_cols:
        if 'count' in col.lower() or 'device' in col.lower():
            total = df[col].sum()
            key_insights.append(f"â€¢ æ€»è®¡ {col.replace('_', ' ')}ï¼š{total:,.0f}")
        elif 'avg' in col.lower() or 'rate' in col.lower():
            avg_val = df[col].mean()
            key_insights.append(f"â€¢ å¹³å‡ {col.replace('_', ' ')}ï¼š{avg_val:.2f}")
    
    return f"""
ğŸ“‹ **æ•°æ®æ¦‚è§ˆ**

â€¢ å…±æŸ¥è¯¢åˆ° {row_count} æ¡è®°å½•
{chr(10).join(key_insights[:3])}

ğŸ’¡ æ›´å¤šè¯¦ç»†ä¿¡æ¯å¯æŸ¥çœ‹å…·ä½“æ•°æ®ã€‚
""".strip()