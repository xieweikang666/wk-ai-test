"""
æ™ºèƒ½åˆ†ææ‰§è¡Œå¼•æ“
æ•´åˆSQLç”Ÿæˆã€è´¨é‡ä¿éšœå’Œåˆ†æç»“æœç”Ÿæˆ
"""
import logging
from typing import Dict, Any, Optional
import pandas as pd

from agent.query_quality_guard import QueryQualityGuard
from agent.intelligent_analyzer import IntelligentAnalyzer
from utils.chart import draw_chart

logger = logging.getLogger(__name__)


class IntelligentQueryEngine:
    """æ™ºèƒ½æŸ¥è¯¢æ‰§è¡Œå¼•æ“"""
    
    def __init__(self):
        """åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“"""
        self.quality_guard = QueryQualityGuard()
        self.analyzer = IntelligentAnalyzer()
    
    def execute_intelligent_query(self, 
                                user_query: str, 
                                query_plan: Dict[str, Any],
                                enable_quality_check: bool = True) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ™ºèƒ½æŸ¥è¯¢
        
        Args:
            user_query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            query_plan: æŸ¥è¯¢è®¡åˆ’
            enable_quality_check: æ˜¯å¦å¯ç”¨è´¨é‡æ£€æŸ¥
            
        Returns:
            å®Œæ•´çš„æŸ¥è¯¢ç»“æœ
        """
        result = {
            "success": False,
            "data": None,
            "analysis": None,
            "chart_path": None,
            "sql": None,
            "quality_report": None,
            "error": None
        }
        
        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œæ™ºèƒ½æŸ¥è¯¢: {user_query}")
            
            if enable_quality_check:
                # å¸¦è´¨é‡æ£€æŸ¥çš„æ‰§è¡Œ
                df, quality_report = self.quality_guard.execute_query_with_quality_check(
                    user_query, query_plan
                )
                result["quality_report"] = quality_report
                
                if df.empty:
                    result["error"] = "æŸ¥è¯¢ç»“æœä¸ºç©ºæˆ–æ‰§è¡Œå¤±è´¥"
                    result["sql"] = "æ‰§è¡Œå¤±è´¥"
                    return result
                
                # å¦‚æœè´¨é‡åˆ†æ•°è¿‡ä½ï¼Œæä¾›è­¦å‘Š
                if quality_report["overall_score"] < 60:
                    logger.warning(f"æŸ¥è¯¢è´¨é‡åˆ†æ•°è¾ƒä½: {quality_report['overall_score']:.1f}")
            else:
                # ç›´æ¥æ‰§è¡Œï¼ˆåŸæœ‰é€»è¾‘ï¼‰
                from agent.intelligent_sql_generator import IntelligentSQLGenerator
                from db.clickhouse_client import get_client
                
                sql_generator = IntelligentSQLGenerator()
                client = get_client()
                
                sql = sql_generator.generate_sql(user_query, query_plan)
                df = client.execute_query(sql)
                result["sql"] = sql
                
                if df is None or df.empty:
                    result["error"] = "æŸ¥è¯¢ç»“æœä¸ºç©º"
                    return result
            
            result["data"] = df
            
            # ç”Ÿæˆæ™ºèƒ½åˆ†æ
            logger.info("å¼€å§‹ç”Ÿæˆæ™ºèƒ½åˆ†æ...")
            analysis = self.analyzer.analyze_with_intelligence(
                df=df,
                user_query=user_query,
                query_plan=query_plan
            )
            result["analysis"] = analysis
            
            # ç”Ÿæˆå›¾è¡¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if query_plan.get("need_chart", False):
                chart_type = query_plan.get("chart_type", "bar")
                try:
                    chart_path = draw_chart(
                        df=df,
                        chart_type=chart_type,
                        title=f"ç½‘ç»œè´¨é‡åˆ†æ - {user_query[:30]}"
                    )
                    result["chart_path"] = chart_path
                    logger.info(f"å›¾è¡¨ç”ŸæˆæˆåŠŸ: {chart_path}")
                except Exception as e:
                    logger.warning(f"å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
            
            result["success"] = True
            logger.info("æ™ºèƒ½æŸ¥è¯¢æ‰§è¡Œå®Œæˆ")
            
            return result
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            result["error"] = f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {str(e)}"
            return result
    
    def get_query_explanation(self, user_query: str, query_plan: Dict[str, Any]) -> str:
        """ç”ŸæˆæŸ¥è¯¢è§£é‡Šè¯´æ˜"""
        
        explanation_parts = [
            f"**æŸ¥è¯¢ç†è§£**ï¼š{user_query}",
            "",
            "**æ‰§è¡Œè®¡åˆ’**ï¼š"
        ]
        
        # è§£ææŸ¥è¯¢è®¡åˆ’çš„å…³é”®ä¿¡æ¯
        metrics = query_plan.get("metrics", [])
        if metrics:
            metric_names = []
            for metric in metrics:
                if metric == "avg_rtt":
                    metric_names.append("å¹³å‡å»¶è¿Ÿ(RTT)")
                elif metric == "avg_lost":
                    metric_names.append("å¹³å‡ä¸¢åŒ…ç‡")
                else:
                    metric_names.append(metric)
            explanation_parts.append(f"- åˆ†ææŒ‡æ ‡ï¼š{', '.join(metric_names)}")
        
        filters = query_plan.get("filters", {})
        time_range = filters.get("time_range", "")
        if time_range:
            explanation_parts.append(f"- æ—¶é—´èŒƒå›´ï¼š{time_range}")
        
        src_isp = filters.get("src_isp", [])
        if src_isp:
            isp_names = []
            for isp in src_isp:
                if isp == "chinatelecom":
                    isp_names.append("ç”µä¿¡")
                elif isp == "chinamobile":
                    isp_names.append("ç§»åŠ¨")
                elif isp == "chinaunicom":
                    isp_names.append("è”é€š")
                else:
                    isp_names.append(isp)
            explanation_parts.append(f"- è¿è¥å•†ç­›é€‰ï¼š{', '.join(isp_names)}")
        
        aggregation = query_plan.get("aggregation", "none")
        if aggregation != "none":
            aggregation_desc = self._get_aggregation_description(aggregation)
            explanation_parts.append(f"- æ•°æ®èšåˆï¼š{aggregation_desc}")
        
        explanation_parts.extend([
            "",
            "**æŸ¥è¯¢ç‰¹ç‚¹**ï¼š",
            "- ä½¿ç”¨æ™ºèƒ½SQLç”Ÿæˆï¼Œç¡®ä¿æŸ¥è¯¢å‡†ç¡®æ€§å’Œæ€§èƒ½",
            "- å¤šç»´åº¦æ•°æ®è´¨é‡æ£€æŸ¥ï¼Œä¿éšœåˆ†æå¯é æ€§",
            "- åŸºäºLLMçš„æ·±åº¦åˆ†æï¼Œæä¾›ä¸ªæ€§åŒ–æ´å¯Ÿ",
            "- è‡ªåŠ¨è¯†åˆ«å¼‚å¸¸å’Œè¶‹åŠ¿ï¼Œç”Ÿæˆå¯æ“ä½œå»ºè®®"
        ])
        
        return "\n".join(explanation_parts)
    
    def _get_aggregation_description(self, aggregation: str) -> str:
        """è·å–èšåˆæ–¹å¼æè¿°"""
        descriptions = {
            "group_by_province": "æŒ‰çœä»½åˆ†ç»„ç»Ÿè®¡",
            "group_by_isp": "æŒ‰è¿è¥å•†åˆ†ç»„ç»Ÿè®¡", 
            "group_by_task": "æŒ‰ä»»åŠ¡ç±»å‹åˆ†ç»„ç»Ÿè®¡",
            "group_by_target_node": "æŒ‰ç›®æ ‡èŠ‚ç‚¹åˆ†ç»„ç»Ÿè®¡",
            "group_by_time_hour": "æŒ‰æ—¶é—´(å°æ—¶)è¶‹åŠ¿åˆ†æ",
            "group_by_province_isp": "æŒ‰çœä»½å’Œè¿è¥å•†äº¤å‰åˆ†æ",
            "group_by_hostname_task": "æŒ‰æ¢æµ‹è®¾å¤‡å’Œä»»åŠ¡ç±»å‹åˆ†æ",
            "group_by_target_node_task": "æŒ‰ç›®æ ‡èŠ‚ç‚¹å’Œä»»åŠ¡ç±»å‹åˆ†æ",
            "group_by_target_node_province_isp": "æŒ‰ç›®æ ‡èŠ‚ç‚¹ã€çœä»½å’Œè¿è¥å•†ç»¼åˆåˆ†æ"
        }
        
        return descriptions.get(aggregation, "è‡ªå®šä¹‰èšåˆæ–¹å¼")
    
    def generate_response_format(self, query_result: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ ‡å‡†åŒ–çš„å“åº”æ ¼å¼"""
        
        if not query_result["success"]:
            return {
                "answer": f"âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥ï¼š{query_result['error']}",
                "chart_url": None,
                "sql": query_result.get("sql"),
                "quality_summary": None
            }
        
        response = {
            "answer": query_result["analysis"],
            "chart_url": query_result.get("chart_path"),
            "sql": query_result.get("sql"),
            "quality_summary": None
        }
        
        # æ·»åŠ è´¨é‡æ‘˜è¦
        quality_report = query_result.get("quality_report")
        if quality_report:
            quality_score = quality_report.get("overall_score", 0)
            if quality_score >= 80:
                quality_emoji = "ğŸŸ¢"
                quality_text = "ä¼˜ç§€"
            elif quality_score >= 60:
                quality_emoji = "ğŸŸ¡"
                quality_text = "è‰¯å¥½"
            else:
                quality_emoji = "ğŸ”´"
                quality_text = "éœ€æ”¹è¿›"
            
            response["quality_summary"] = f"{quality_emoji} æŸ¥è¯¢è´¨é‡ï¼š{quality_text} ({quality_score:.1f}/100)"
        
        return response


# å‘åå…¼å®¹çš„åŒ…è£…å™¨
def create_enhanced_functions_executor():
    """åˆ›å»ºå¢å¼ºç‰ˆå‡½æ•°æ‰§è¡Œå™¨ï¼Œä¿æŒä¸åŸæœ‰ä»£ç çš„å…¼å®¹æ€§"""
    
    class EnhancedQueryExecutor:
        """å¢å¼ºç‰ˆæŸ¥è¯¢æ‰§è¡Œå™¨"""
        
        def __init__(self):
            self.engine = IntelligentQueryEngine()
        
        def run_query(self, query_plan: Dict[str, Any]) -> pd.DataFrame:
            """æ‰§è¡ŒæŸ¥è¯¢ï¼ˆå…¼å®¹åŸæ¥å£ï¼‰"""
            original_query = query_plan.get("original_query", "")
            
            # ä½¿ç”¨æ™ºèƒ½å¼•æ“æ‰§è¡ŒæŸ¥è¯¢
            result = self.engine.execute_intelligent_query(
                user_query=original_query,
                query_plan=query_plan,
                enable_quality_check=True  # é»˜è®¤å¯ç”¨è´¨é‡æ£€æŸ¥
            )
            
            if result["success"]:
                # ç¼“å­˜ç»“æœä¾›å…¶ä»–æ–¹æ³•ä½¿ç”¨
                self._last_result = result
                return result["data"]
            else:
                raise Exception(f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {result['error']}")
        
        def get_generated_sql(self, query_plan: Dict[str, Any]) -> str:
            """è·å–ç”Ÿæˆçš„SQLï¼ˆå…¼å®¹åŸæ¥å£ï¼‰"""
            if hasattr(self, '_last_result') and self._last_result:
                return self._last_result.get("sql", "")
            
            # å¦‚æœæ²¡æœ‰ç¼“å­˜çš„æŸ¥è¯¢ç»“æœï¼Œé‡æ–°ç”ŸæˆSQL
            from agent.intelligent_sql_generator import IntelligentSQLGenerator
            generator = IntelligentSQLGenerator()
            original_query = query_plan.get("original_query", "")
            return generator.generate_sql(original_query, query_plan)
        
        def explain_result(self, 
                          df: pd.DataFrame,
                          query_plan: Dict[str, Any], 
                          chart_path: Optional[str] = None) -> str:
            """è§£é‡Šç»“æœï¼ˆå…¼å®¹åŸæ¥å£ï¼‰"""
            if hasattr(self, '_last_result') and self._last_result:
                return self._last_result.get("analysis", "")
            
            # å¦‚æœæ²¡æœ‰ç¼“å­˜çš„åˆ†æç»“æœï¼Œé‡æ–°ç”Ÿæˆåˆ†æ
            original_query = query_plan.get("original_query", "")
            analysis = self.engine.analyzer.analyze_with_intelligence(
                df=df,
                user_query=original_query,
                query_plan=query_plan,
                chart_path=chart_path
            )
            return analysis
        
        def draw_chart_wrapper(self, 
                             df: pd.DataFrame,
                             chart_type: str = "line",
                             title: Optional[str] = None) -> Optional[str]:
            """ç”Ÿæˆå›¾è¡¨ï¼ˆå…¼å®¹åŸæ¥å£ï¼‰"""
            try:
                return draw_chart(df=df, chart_type=chart_type, title=title)
            except Exception as e:
                logger.error(f"å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
                return None
    
    return EnhancedQueryExecutor()


# å…¨å±€æ‰§è¡Œå™¨å®ä¾‹
_enhanced_executor = None

def get_enhanced_executor():
    """è·å–å¢å¼ºç‰ˆæ‰§è¡Œå™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _enhanced_executor
    
    if _enhanced_executor is not None:
        return _enhanced_executor
    
    _enhanced_executor = create_enhanced_functions_executor()
    return _enhanced_executor