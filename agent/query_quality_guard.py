"""
æŸ¥è¯¢è´¨é‡ä¿éšœç³»ç»Ÿ
ç¡®ä¿SQLç”Ÿæˆå’Œåˆ†æç»“æœçš„è´¨é‡
"""
import logging
from typing import Dict, Any, List, Optional, Tuple
import pandas as pd
import json
import time

from agent.intelligent_sql_generator import IntelligentSQLGenerator
from agent.intelligent_analyzer import IntelligentAnalyzer
from agent.llm import get_llm_client
from db.clickhouse_client import get_client

logger = logging.getLogger(__name__)


class QueryQualityGuard:
    """æŸ¥è¯¢è´¨é‡ä¿éšœç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–è´¨é‡ä¿éšœç³»ç»Ÿ"""
        self.sql_generator = IntelligentSQLGenerator()
        self.analyzer = IntelligentAnalyzer()
        self.llm = get_llm_client()
        self.client = get_client()
    
    def execute_query_with_quality_check(self, 
                                       user_query: str, 
                                       query_plan: Dict[str, Any]) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """
        æ‰§è¡Œå¸¦è´¨é‡æ£€æŸ¥çš„æŸ¥è¯¢
        
        Returns:
            (æŸ¥è¯¢ç»“æœDataFrame, è´¨é‡æŠ¥å‘Š)
        """
        quality_report = {
            "sql_generation": {"status": "pending", "issues": [], "score": 0},
            "execution": {"status": "pending", "issues": [], "execution_time": 0},
            "result_quality": {"status": "pending", "issues": [], "score": 0},
            "overall_score": 0
        }
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šSQLç”Ÿæˆè´¨é‡æ£€æŸ¥
            sql, sql_quality = self._generate_and_validate_sql(user_query, query_plan)
            quality_report["sql_generation"] = sql_quality
            
            if sql_quality["status"] == "failed":
                return pd.DataFrame(), quality_report
            
            # ç¬¬äºŒæ­¥ï¼šæ‰§è¡ŒæŸ¥è¯¢å¹¶ç›‘æ§
            start_time = time.time()
            df, execution_quality = self._execute_with_monitoring(sql)
            execution_time = time.time() - start_time
            
            quality_report["execution"] = execution_quality
            quality_report["execution"]["execution_time"] = execution_time
            
            if execution_quality["status"] == "failed":
                return pd.DataFrame(), quality_report
            
            # ç¬¬ä¸‰æ­¥ï¼šç»“æœè´¨é‡è¯„ä¼°
            result_quality = self._evaluate_result_quality(df, query_plan)
            quality_report["result_quality"] = result_quality
            
            # ç¬¬å››æ­¥ï¼šè®¡ç®—æ€»ä½“è´¨é‡åˆ†æ•°
            quality_report["overall_score"] = self._calculate_overall_score(quality_report)
            
            return df, quality_report
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢è´¨é‡æ£€æŸ¥å¤±è´¥: {e}")
            quality_report["sql_generation"]["status"] = "failed"
            quality_report["sql_generation"]["issues"].append(f"ç³»ç»Ÿå¼‚å¸¸: {str(e)}")
            return pd.DataFrame(), quality_report
    
    def _generate_and_validate_sql(self, user_query: str, query_plan: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
        """ç”Ÿæˆå¹¶éªŒè¯SQLè´¨é‡"""
        
        try:
            # ç”ŸæˆSQL
            sql = self.sql_generator.generate_sql(user_query, query_plan)
            
            # è´¨é‡æ£€æŸ¥
            issues = []
            score = 100
            
            # 1. è¯­æ³•å’Œå®‰å…¨æ€§æ£€æŸ¥
            validation_result = self.sql_generator.validate_sql_execution(sql)
            if not validation_result["valid"]:
                return "", {"status": "failed", "issues": [validation_result["message"]], "score": 0}
            
            # 2. å¤æ‚åº¦æ£€æŸ¥
            complexity_score = self._check_sql_complexity(sql)
            score = min(score, complexity_score["score"])
            issues.extend(complexity_score["issues"])
            
            # 3. æ€§èƒ½æ£€æŸ¥
            performance_score = self._estimate_sql_performance(sql)
            score = min(score, performance_score["score"])
            issues.extend(performance_score["issues"])
            
            # 4. è¯­ä¹‰åŒ¹é…åº¦æ£€æŸ¥
            semantic_score = self._check_semantic_alignment(sql, user_query)
            score = min(score, semantic_score["score"])
            issues.extend(semantic_score["issues"])
            
            status = "passed" if score >= 70 else "warning"
            
            return sql, {"status": status, "issues": issues, "score": score}
            
        except Exception as e:
            return "", {"status": "failed", "issues": [f"SQLç”Ÿæˆå¼‚å¸¸: {str(e)}"], "score": 0}
    
    def _check_sql_complexity(self, sql: str) -> Dict[str, Any]:
        """æ£€æŸ¥SQLå¤æ‚åº¦"""
        issues = []
        score = 100
        
        sql_lower = sql.lower()
        
        # æ£€æŸ¥JOINæ•°é‡
        join_count = sql_lower.count(' join ')
        if join_count > 3:
            score -= 20
            issues.append(f"JOINæ•°é‡è¿‡å¤š({join_count})ï¼Œå¯èƒ½å½±å“æ€§èƒ½")
        
        # æ£€æŸ¥å­æŸ¥è¯¢æ·±åº¦
        subquery_depth = sql_lower.count('(select')
        if subquery_depth > 2:
            score -= 15
            issues.append(f"å­æŸ¥è¯¢è¿‡æ·±({subquery_depth}å±‚)ï¼Œå»ºè®®ç®€åŒ–")
        
        # æ£€æŸ¥èšåˆå‡½æ•°å¤æ‚åº¦
        aggregate_functions = ['count(', 'avg(', 'sum(', 'max(', 'min(']
        aggregate_count = sum(sql_lower.count(func) for func in aggregate_functions)
        if aggregate_count > 10:
            score -= 10
            issues.append(f"èšåˆå‡½æ•°è¿‡å¤š({aggregate_count})ï¼ŒæŸ¥è¯¢å¯èƒ½è¿‡äºå¤æ‚")
        
        return {"score": max(0, score), "issues": issues}
    
    def _estimate_sql_performance(self, sql: str) -> Dict[str, Any]:
        """ä¼°ç®—SQLæ€§èƒ½"""
        issues = []
        score = 100
        
        sql_lower = sql.lower()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´è¿‡æ»¤
        if 'timestamp' not in sql_lower:
            score -= 30
            issues.append("ç¼ºå°‘æ—¶é—´è¿‡æ»¤æ¡ä»¶ï¼Œå¯èƒ½å¯¼è‡´å…¨è¡¨æ‰«æ")
        
        # æ£€æŸ¥LIMIT
        if 'limit' not in sql_lower:
            score -= 20
            issues.append("ç¼ºå°‘LIMITé™åˆ¶ï¼Œå¯èƒ½è¿”å›å¤§é‡æ•°æ®")
        else:
            # æ£€æŸ¥LIMITå€¼
            import re
            limit_match = re.search(r'limit\s+(\d+)', sql_lower)
            if limit_match:
                limit_value = int(limit_match.group(1))
                if limit_value > 1000000:
                    score -= 15
                    issues.append(f"LIMITå€¼è¿‡å¤§({limit_value})ï¼Œå»ºè®®åˆ†é¡µæŸ¥è¯¢")
        
        # æ£€æŸ¥SELECT *
        if 'select *' in sql_lower:
            score -= 10
            issues.append("ä½¿ç”¨SELECT *å¯èƒ½å½±å“æ€§èƒ½ï¼Œå»ºè®®æŒ‡å®šå…·ä½“å­—æ®µ")
        
        return {"score": max(0, score), "issues": issues}
    
    def _check_semantic_alignment(self, sql: str, user_query: str) -> Dict[str, Any]:
        """æ£€æŸ¥SQLä¸æŸ¥è¯¢æ„å›¾çš„åŒ¹é…åº¦"""
        issues = []
        
        prompt = f"""
è¯·è¯„ä¼°ä»¥ä¸‹SQLæ˜¯å¦èƒ½å¤Ÿå‡†ç¡®å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{user_query}

ç”Ÿæˆçš„SQLï¼š
{sql}

è¯·ä»ä»¥ä¸‹è§’åº¦è¯„ä¼°ï¼š
1. å­—æ®µé€‰æ‹©æ˜¯å¦åˆç†
2. èšåˆæ–¹å¼æ˜¯å¦æ°å½“  
3. è¿‡æ»¤æ¡ä»¶æ˜¯å¦å®Œæ•´
4. ç»“æœæ˜¯å¦èƒ½å›ç­”ç”¨æˆ·é—®é¢˜

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "alignment_score": 0-100çš„åŒ¹é…åº¦åˆ†æ•°,
    "field_appropriateness": "å­—æ®µé€‰æ‹©è¯„ä¼°",
    "aggregation_appropriateness": "èšåˆæ–¹å¼è¯„ä¼°", 
    "filter_completeness": "è¿‡æ»¤æ¡ä»¶è¯„ä¼°",
    "result_relevance": "ç»“æœç›¸å…³æ€§è¯„ä¼°",
    "suggestions": ["æ”¹è¿›å»ºè®®"]
}}
"""
        
        try:
            response = self.llm.chat([{"role": "user", "content": prompt}], temperature=0.1)
            if response and response.get("content"):
                evaluation = json.loads(response["content"].strip())
                score = evaluation.get("alignment_score", 50)
                
                if score < 70:
                    issues.extend(evaluation.get("suggestions", ["SQLä¸æŸ¥è¯¢æ„å›¾åŒ¹é…åº¦è¾ƒä½"]))
                
                return {"score": score, "issues": issues}
                
        except Exception as e:
            logger.warning(f"è¯­ä¹‰åŒ¹é…åº¦æ£€æŸ¥å¤±è´¥: {e}")
        
        return {"score": 75, "issues": []}
    
    def _execute_with_monitoring(self, sql: str) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """æ‰§è¡ŒæŸ¥è¯¢å¹¶ç›‘æ§"""
        issues = []
        
        try:
            # æ‰§è¡ŒæŸ¥è¯¢
            df = self.client.execute_query(sql)
            
            if df is None:
                return pd.DataFrame(), {"status": "failed", "issues": ["æŸ¥è¯¢è¿”å›ç©ºç»“æœ"], "score": 0}
            
            # æ£€æŸ¥ç»“æœå¤§å°
            row_count = len(df)
            if row_count == 0:
                issues.append("æŸ¥è¯¢ç»“æœä¸ºç©º")
                return df, {"status": "warning", "issues": issues, "score": 60}
            elif row_count < 10:
                issues.append(f"æŸ¥è¯¢ç»“æœè¾ƒå°‘({row_count}è¡Œ)ï¼Œåˆ†æå¯èƒ½ä¸å¤Ÿå…¨é¢")
            elif row_count > 100000:
                issues.append(f"æŸ¥è¯¢ç»“æœè¾ƒå¤š({row_count}è¡Œ)ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥èšåˆ")
            
            # æ£€æŸ¥åˆ—å®Œæ•´æ€§
            if df.columns.empty:
                issues.append("æŸ¥è¯¢ç»“æœç¼ºå°‘åˆ—ä¿¡æ¯")
                return df, {"status": "failed", "issues": issues, "score": 0}
            
            score = 100 - len(issues) * 10
            status = "passed" if score >= 70 else "warning"
            
            return df, {"status": status, "issues": issues, "score": max(0, score)}
            
        except Exception as e:
            return pd.DataFrame(), {"status": "failed", "issues": [f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {str(e)}"], "score": 0}
    
    def _evaluate_result_quality(self, df: pd.DataFrame, query_plan: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°ç»“æœæ•°æ®è´¨é‡"""
        issues = []
        score = 100
        
        # 1. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        completeness_score = self._check_data_completeness(df)
        score = min(score, completeness_score["score"])
        issues.extend(completeness_score["issues"])
        
        # 2. æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
        consistency_score = self._check_data_consistency(df)
        score = min(score, consistency_score["score"])
        issues.extend(consistency_score["issues"])
        
        # 3. æ•°æ®åˆ†å¸ƒåˆç†æ€§æ£€æŸ¥
        distribution_score = self._check_data_distribution(df)
        score = min(score, distribution_score["score"])
        issues.extend(distribution_score["issues"])
        
        # 4. æŸ¥è¯¢è®¡åˆ’åŒ¹é…åº¦æ£€æŸ¥
        plan_alignment = self._check_plan_alignment(df, query_plan)
        score = min(score, plan_alignment["score"])
        issues.extend(plan_alignment["issues"])
        
        status = "passed" if score >= 70 else "warning"
        
        return {"status": status, "issues": issues, "score": max(0, score)}
    
    def _check_data_completeness(self, df: pd.DataFrame) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        issues = []
        score = 100
        
        # ç¼ºå¤±å€¼æ£€æŸ¥
        missing_analysis = {}
        for col in df.columns:
            missing_count = df[col].isnull().sum()
            if missing_count > 0:
                missing_rate = missing_count / len(df)
                missing_analysis[col] = missing_rate
                
                if missing_rate > 0.5:
                    score -= 20
                    issues.append(f"åˆ—{col}ç¼ºå¤±å€¼è¿‡å¤š({missing_rate:.1%})")
                elif missing_rate > 0.1:
                    score -= 10
                    issues.append(f"åˆ—{col}å­˜åœ¨è¾ƒå¤šç¼ºå¤±å€¼({missing_rate:.1%})")
        
        # å…³é”®å­—æ®µæ£€æŸ¥
        key_fields = ['avg_rtt', 'avg_lost', 'hostname', 'target_node']
        for field in key_fields:
            if field in df.columns:
                missing_rate = df[field].isnull().sum() / len(df)
                if missing_rate > 0.2:
                    score -= 15
                    issues.append(f"å…³é”®å­—æ®µ{field}ç¼ºå¤±ç‡è¿‡é«˜({missing_rate:.1%})")
        
        return {"score": max(0, score), "issues": issues}
    
    def _check_data_consistency(self, df: pd.DataFrame) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§"""
        issues = []
        score = 100
        
        # æ•°å€¼èŒƒå›´æ£€æŸ¥
        if 'avg_lost' in df.columns:
            # ä¸¢åŒ…ç‡åº”è¯¥åœ¨0-1ä¹‹é—´
            invalid_loss = ((df['avg_lost'] < 0) | (df['avg_lost'] > 1)).sum()
            if invalid_loss > 0:
                invalid_rate = invalid_loss / len(df)
                score -= min(30, invalid_rate * 100)
                issues.append(f"ä¸¢åŒ…ç‡æ•°æ®å¼‚å¸¸({invalid_rate:.1%}çš„æ•°æ®è¶…å‡º0-1èŒƒå›´)")
        
        if 'avg_rtt' in df.columns:
            # RTTåº”è¯¥ä¸ºæ­£æ•°
            invalid_rtt = (df['avg_rtt'] < 0).sum()
            if invalid_rtt > 0:
                invalid_rate = invalid_rtt / len(df)
                score -= min(25, invalid_rate * 100)
                issues.append(f"RTTæ•°æ®å¼‚å¸¸({invalid_rate:.1%}çš„æ•°æ®ä¸ºè´Ÿæ•°)")
        
        return {"score": max(0, score), "issues": issues}
    
    def _check_data_distribution(self, df: pd.DataFrame) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®åˆ†å¸ƒåˆç†æ€§"""
        issues = []
        score = 100
        
        # æ£€æŸ¥æ•°æ®åˆ†å¸ƒæ˜¯å¦è¿‡äºé›†ä¸­
        for col in ['avg_rtt', 'avg_lost']:
            if col in df.columns:
                data = df[col].dropna()
                if len(data) > 1:
                    # æ£€æŸ¥æ ‡å‡†å·®
                    std_val = data.std()
                    mean_val = data.mean()
                    
                    if mean_val > 0:
                        cv = std_val / mean_val  # å˜å¼‚ç³»æ•°
                        
                        if cv < 0.01:  # æ•°æ®è¿‡äºé›†ä¸­
                            score -= 15
                            issues.append(f"{col}æ•°æ®åˆ†å¸ƒè¿‡äºé›†ä¸­ï¼Œå¯èƒ½ç¼ºä¹ä»£è¡¨æ€§")
                        elif cv > 5:  # æ•°æ®è¿‡äºåˆ†æ•£
                            score -= 10
                            issues.append(f"{col}æ•°æ®å˜å¼‚ç³»æ•°è¾ƒå¤§({cv:.2f})ï¼Œå¯èƒ½å­˜åœ¨å¼‚å¸¸å€¼")
        
        return {"score": max(0, score), "issues": issues}
    
    def _check_plan_alignment(self, df: pd.DataFrame, query_plan: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æŸ¥ç»“æœä¸æŸ¥è¯¢è®¡åˆ’çš„ä¸€è‡´æ€§"""
        issues = []
        score = 100
        
        # æ£€æŸ¥é¢„æœŸçš„æŒ‡æ ‡æ˜¯å¦å­˜åœ¨
        expected_metrics = query_plan.get("metrics", [])
        for metric in expected_metrics:
            if metric not in df.columns:
                score -= 20
                issues.append(f"ç¼ºå°‘é¢„æœŸæŒ‡æ ‡{metric}")
        
        # æ£€æŸ¥èšåˆç»´åº¦
        aggregation = query_plan.get("aggregation", "none")
        if aggregation != "none":
            # è§£æé¢„æœŸåº”è¯¥æœ‰çš„åˆ†ç»„å­—æ®µ
            expected_group_fields = []
            if "hostname" in aggregation:
                expected_group_fields.append("hostname")
            if "target_node" in aggregation:
                expected_group_fields.append("target_node")
            if "src_isp" in aggregation:
                expected_group_fields.append("src_isp")
            if "src_province" in aggregation:
                expected_group_fields.append("src_province")
            
            for field in expected_group_fields:
                if field not in df.columns:
                    score -= 15
                    issues.append(f"ç¼ºå°‘é¢„æœŸåˆ†ç»„å­—æ®µ{field}")
        
        return {"score": max(0, score), "issues": issues}
    
    def _calculate_overall_score(self, quality_report: Dict[str, Any]) -> float:
        """è®¡ç®—æ€»ä½“è´¨é‡åˆ†æ•°"""
        weights = {
            "sql_generation": 0.3,
            "execution": 0.2,
            "result_quality": 0.5
        }
        
        total_score = 0
        total_weight = 0
        
        for component, weight in weights.items():
            component_score = quality_report.get(component, {}).get("score", 0)
            total_score += component_score * weight
            total_weight += weight
        
        return total_score / total_weight if total_weight > 0 else 0
    
    def generate_quality_report(self, quality_report: Dict[str, Any]) -> str:
        """ç”Ÿæˆç”¨æˆ·å‹å¥½çš„è´¨é‡æŠ¥å‘Š"""
        report_lines = []
        
        overall_score = quality_report.get("overall_score", 0)
        
        if overall_score >= 80:
            report_lines.append("ğŸŸ¢ **æŸ¥è¯¢è´¨é‡è¯„ä¼°ï¼šä¼˜ç§€**")
        elif overall_score >= 60:
            report_lines.append("ğŸŸ¡ **æŸ¥è¯¢è´¨é‡è¯„ä¼°ï¼šè‰¯å¥½**")
        else:
            report_lines.append("ğŸ”´ **æŸ¥è¯¢è´¨é‡è¯„ä¼°ï¼šéœ€è¦æ”¹è¿›**")
        
        report_lines.append(f"æ€»ä½“è¯„åˆ†ï¼š{overall_score:.1f}/100")
        
        # å„ç»„ä»¶è¯¦ç»†æŠ¥å‘Š
        components = {
            "sql_generation": "SQLç”Ÿæˆ",
            "execution": "æŸ¥è¯¢æ‰§è¡Œ", 
            "result_quality": "ç»“æœè´¨é‡"
        }
        
        for comp_key, comp_name in components.items():
            comp_data = quality_report.get(comp_key, {})
            score = comp_data.get("score", 0)
            status = comp_data.get("status", "unknown")
            issues = comp_data.get("issues", [])
            
            if status == "passed":
                status_emoji = "âœ…"
            elif status == "warning":
                status_emoji = "âš ï¸"
            else:
                status_emoji = "âŒ"
            
            report_lines.append(f"\n{status_emoji} **{comp_name}**ï¼š{score:.1f}/100")
            
            if issues:
                for issue in issues[:2]:  # æœ€å¤šæ˜¾ç¤º2ä¸ªé—®é¢˜
                    report_lines.append(f"   â€¢ {issue}")
        
        return "\n".join(report_lines)